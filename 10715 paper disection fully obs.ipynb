{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LQG optimal controrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "from plot_ult import * \n",
    "\n",
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LQG\n",
    "\n",
    "max_linear_velocity = 2.0 # meters per second\n",
    "max_angular_velocity = 1.5708 # radians per second\n",
    "\n",
    "\n",
    "def state_space_model(A, state_t_minus_1, B, control_input_t_minus_1):\n",
    "    '''\n",
    "    1d world model.\n",
    "    the task is to use contorl to move state to 0\n",
    "    the dynamic is linear, defined in A.\n",
    "    the control is clipped.\n",
    "\n",
    "    input:\n",
    "    A, linear state trainsition\n",
    "    B, linear control matrix\n",
    "\n",
    "    '''\n",
    "    # make sure control with in range\n",
    "    control_input_t_minus_1[0] = np.clip(control_input_t_minus_1[0],\n",
    "                                                                            -max_linear_velocity,\n",
    "                                                                            max_linear_velocity)\n",
    "    # control_input_t_minus_1[1] = np.clip(control_input_t_minus_1[1], -max_angular_velocity,max_angular_velocity)\n",
    "    \n",
    "    # prediction\n",
    "    state_estimate_t = (A @ state_t_minus_1) + (B @ control_input_t_minus_1) \n",
    "             \n",
    "    return state_estimate_t\n",
    "\n",
    "\n",
    "def lqr(actual_state_x, desired_state_xf, Q, R, A, B):\n",
    "    \"\"\"\n",
    "    Discrete-time linear quadratic regulator for a nonlinear system.\n",
    " \n",
    "    Compute the optimal control inputs given a nonlinear system, cost matrices, \n",
    "    current state, and a final state.\n",
    "     \n",
    "    Compute the control variables that minimize the cumulative cost.\n",
    " \n",
    "    Solve for P using the dynamic programming method.\n",
    " \n",
    "    :param actual_state_x: The current state of the system \n",
    "        3x1 NumPy Array given the state is [x,y,yaw angle] --->\n",
    "        [meters, meters, radians]\n",
    "    :param desired_state_xf: The desired state of the system\n",
    "        3x1 NumPy Array given the state is [x,y,yaw angle] --->\n",
    "        [meters, meters, radians]   \n",
    "    Q: The state cost matrix\n",
    "        3x3 NumPy Array\n",
    "    R: The input cost matrix\n",
    "        2x2 NumPy Array\n",
    "    :param dt: The size of the timestep in seconds -> float\n",
    " \n",
    "    :return: u_star: Optimal action u for the current state \n",
    "        2x1 NumPy Array given the control input vector is\n",
    "        [linear velocity of the car, angular velocity of the car]\n",
    "        [meters per second, radians per second]\n",
    "    \"\"\"\n",
    "    # We want the system to stabilize at desired_state_xf.\n",
    "    x_error = actual_state_x - desired_state_xf\n",
    "    N = 50\n",
    "    P = [None] * (N + 1)\n",
    "    Qf = Q\n",
    "    # LQR via Dynamic Programming\n",
    "    P[N] = Qf\n",
    "    # For i = N, ..., 1\n",
    "    for i in range(N, 0, -1):\n",
    "        # Discrete-time Algebraic Riccati equation to calculate the optimal \n",
    "        # state cost matrix\n",
    "        P[i-1] = Q + A.T @ P[i] @ A - (A.T @ P[i] @ B) @ np.linalg.pinv(\n",
    "            R + B.T @ P[i] @ B) @ (B.T @ P[i] @ A)      \n",
    "    # Create a list of N elements\n",
    "    K = [None] * N\n",
    "    u = [None] * N\n",
    "    # For i = 0, ..., N - 1\n",
    "    for i in range(N):\n",
    "        # Calculate the optimal feedback gain K\n",
    "        K[i] = -np.linalg.pinv(R + B.T @ P[i+1] @ B) @ B.T @ P[i+1] @ A\n",
    "        u[i] = K[i] @ x_error\n",
    "    u_star = u[N-2]\n",
    "    return u_star\n",
    " \n",
    "\n",
    "def lqr(x, xf, Q, R, A, B, N=50):\n",
    "    x_error = x - xf\n",
    "    P = [None] * (N + 1)\n",
    "    Qf = Q\n",
    "    P[N] = Qf\n",
    "    K = [None] * N # control gain\n",
    "    u = [None] * N # control\n",
    "\n",
    "    for i in range(N, 0, -1):\n",
    "        P[i-1] = Q + A.T @ P[i] @ A - (A.T @ P[i] @ B) @ np.linalg.pinv(\n",
    "            R + B.T @ P[i] @ B) @ (B.T @ P[i] @ A)   \n",
    "           \n",
    "    for i in range(N):\n",
    "        K[i] = -np.linalg.pinv(R + B.T @ P[i+1] @ B) @ B.T @ P[i+1] @ A\n",
    "        u[i] = K[i] @ x_error\n",
    "\n",
    "    u_star = u[N-2]\n",
    "    return u_star\n",
    " \n",
    " \n",
    "def kf(x,P, y, u, A, B, H, Q_kf, R_kf,):\n",
    "    \n",
    "    x_hat=A@x + B@u\n",
    "    P_hat=A@P@A.T + Q_kf\n",
    "\n",
    "    err = y - H@x_hat\n",
    "    S = H@P_hat@H.T + R_kf\n",
    "    # print(P_hat, H, S)\n",
    "    Kf = P_hat@H.T@np.linalg.pinv(S)\n",
    "\n",
    "    x=x_hat +Kf@err\n",
    "    P=P_hat - Kf@H@P_hat\n",
    "\n",
    "    return x, P\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Goal Has Been Reached Successfully!\n",
      "Current State = [[ 0.091]\n",
      " [-0.013]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'time')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# const\n",
    "dt = 0.1\n",
    "tau = 0.5\n",
    "tau_a=np.exp(-dt/tau)\n",
    "actual_state_x = np.array([[1.],[0]]) \n",
    "desired_state_xf = np.array([[0.],[0.]])  \n",
    "estimated_state_x=actual_state_x\n",
    "\n",
    "\n",
    "A=np.array([[1.,dt],[0.,1-tau_a]])\n",
    "B=np.array([[0.],[tau_a]])\n",
    "\n",
    "R=np.ones((1,1))*0.8\n",
    "Q = np.array([[1, 0],\n",
    "            [0, .01]])\n",
    "\n",
    "Q_kf=np.array([[0, 0],\n",
    "            [0, .1]])\n",
    "R_kf=np.array([[0.1]])\n",
    "H=np.array([[0,1]])\n",
    "P=np.diag([0.001,0.001])\n",
    "\n",
    "\n",
    "# run the task\n",
    "xs, x_hats=[],[]\n",
    "us=[]\n",
    "# Launch the robot, and have it move to the desired goal destination\n",
    "for i in range(333):\n",
    "    if i%10==0:\n",
    "        # print(f'iteration = {i/10} seconds')\n",
    "        # print(f'Current State = {actual_state_x}, Desired State = {desired_state_xf}')\n",
    "\n",
    "        state_error = actual_state_x - desired_state_xf\n",
    "        state_error_magnitude = np.linalg.norm(state_error)     \n",
    "        # print(f'State Error Magnitude = {state_error_magnitude}')\n",
    "        \n",
    "    # LQR returns the optimal control input\n",
    "    optimal_control_input = lqr(estimated_state_x, \n",
    "                                desired_state_xf, \n",
    "                                Q, R, A, B) \n",
    "        \n",
    "    # print(f'Control Input = {optimal_control_input}')\n",
    "                                    \n",
    "    # We apply the optimal control to the robot\n",
    "    # so we can get a new actual (estimated) state.\n",
    "    actual_state_x = state_space_model(A, actual_state_x, B, \n",
    "                                    optimal_control_input)  \n",
    "    \n",
    "    y=H@actual_state_x+np.random.normal(0, R_kf) # the observation\n",
    "    estimated_state_x,P = kf(estimated_state_x,P,y,optimal_control_input, A, B, H, Q_kf, R_kf)\n",
    "    xs.append(actual_state_x);x_hats.append(estimated_state_x)\n",
    "    us.append(optimal_control_input)\n",
    "    # print(estimated_state_x,actual_state_x,P)\n",
    "    # Stop as soon as we reach the goal\n",
    "    # Feel free to change this threshold value.\n",
    "    if state_error_magnitude < 0.1:\n",
    "        print(\"\\nGoal Has Been Reached Successfully!\")\n",
    "        print(f'Current State = {actual_state_x}')\n",
    "        break\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot([x[0,0] for x in xs], 'r', label='state (pos)')\n",
    "plt.plot(np.array(us).reshape(-1), label='control')\n",
    "plt.legend()\n",
    "plt.ylabel('quantity au (target = 0)')\n",
    "plt.xlabel('time')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Task():\n",
    "\n",
    "    def __init__(self,A, B, H, R, init,target, timeout=333) -> None:\n",
    "        '''\n",
    "        A, state trainsition\n",
    "        B, control\n",
    "        \n",
    "        H, observation (can be partial. shoudl be a bineary matrix)\n",
    "        \n",
    "        Q, state cost\n",
    "        R, control cost\n",
    "        '''\n",
    "        self.A=A\n",
    "        self.B=B\n",
    "        self.R=R\n",
    "        self.H=H\n",
    "        self.init=init # init state\n",
    "        self.target=target # target state\n",
    "        self.timeout=timeout\n",
    "\n",
    "    def reset(self,):\n",
    "        self.s=self.init\n",
    "        # logging\n",
    "        self.t=0\n",
    "        self.xs=[] \n",
    "        self.us=[]\n",
    "        self.rs=[]\n",
    "        return H@self.s\n",
    "    \n",
    "    def is_done(self,):\n",
    "        state_error = self.s - self.target\n",
    "        state_error_magnitude = np.linalg.norm(state_error) \n",
    "        rewarded=state_error_magnitude<0.1\n",
    "        timeout=self.t>self.timeout\n",
    "\n",
    "        return rewarded | timeout\n",
    "\n",
    "    def compute_reward(self,a, scale=100):\n",
    "        '''\n",
    "        compute reward. use the same action cost as LQG, but use binary real reward\n",
    "        '''\n",
    "        state_error = self.s - self.target\n",
    "        state_error_magnitude = np.linalg.norm(state_error) \n",
    "        state_reward=int(state_error_magnitude<0.1)*scale\n",
    "\n",
    "        action_cost=a@self.R@a.T\n",
    "\n",
    "        return state_reward-action_cost\n",
    "\n",
    "    def step(self,a):\n",
    "        next_s = state_space_model(self.A, self.s, self.B, \n",
    "                                    a) \n",
    "        self.s=next_s\n",
    "\n",
    "        reward=self.compute_reward(a)\n",
    "        done = self.is_done()\n",
    "        \n",
    "        \n",
    "        self.xs.append(self.s)\n",
    "        self.us.append(a)\n",
    "        self.rs.append(reward)\n",
    "\n",
    "        self.t+=1\n",
    "        return self.H@self.s, reward, done\n",
    "\n",
    "\n",
    "# actual_state_x = np.array([[1.],[0]]) \n",
    "# desired_state_xf = np.array([[0.],[0.]])  \n",
    "# env=Task(A, B, H, R, actual_state_x,desired_state_xf)\n",
    "# obs=env.reset()\n",
    "\n",
    "# done=False\n",
    "# while not done:\n",
    "#     action = np.ones((1,1))*-1\n",
    "#     # print(action)\n",
    "#     obs, reward, done = env.step(np.array(action)) #track true next_x of monkey\n",
    "    \n",
    "    \n",
    "# plt.plot([s[0,0] for s in env.xs[:555]])\n",
    "# plt.plot([s[0,0] for s in env.us[:555]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam # use Adam optimizer for deep neural net\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import random\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "\n",
    "def init_weights(m, mean=0, std=0.1, bias=0):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean, std)\n",
    "        nn.init.constant_(m.bias, bias)\n",
    "    if isinstance(m, nn.LSTM):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, bias)\n",
    "            elif 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            else:\n",
    "                raise ValueError()\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(target_param.data * (1.0 - tau) + param.data * tau)\n",
    "\n",
    "def hard_update(target, source):\n",
    "    for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "        target_param.data.copy_(param.data)\n",
    "\n",
    "def variable(x, **kwargs):\n",
    "    if torch.cuda.is_available():\n",
    "        return Variable(x, **kwargs).cuda()\n",
    "    return Variable(x, **kwargs)\n",
    "\n",
    "Transition = namedtuple(\n",
    "    'Transition', ('state', 'action', 'done', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity, priority=False):\n",
    "        self.capacity = capacity\n",
    "        self.priority = priority\n",
    "        if priority:\n",
    "            self.memory = PER(capacity=capacity)\n",
    "        else:\n",
    "            self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, *args, err=None):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if self.priority:\n",
    "            assert err is not None, \"Need to pass float error to add to priority memory\"\n",
    "            self.memory.add(err, Transition(*args))\n",
    "        else:\n",
    "            self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        if self.priority:\n",
    "            batch, idx, is_weights = self.memory.sample(batch_size)\n",
    "        else:\n",
    "            batch = random.sample(self.memory, batch_size)\n",
    "            idx = None\n",
    "        batch = Transition(*zip(*batch))\n",
    "        return batch, idx\n",
    "\n",
    "    def update(self, idx, err):\n",
    "        assert self.priority, \"Cannot call this function if not priority memory\"\n",
    "        self.memory.update(idx, err)\n",
    "\n",
    "    def batch_update(self, ids, errs):\n",
    "        for idx, err in zip(ids, errs):\n",
    "            self.update(idx, err)\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    \n",
    "class Agent():\n",
    "\n",
    "    def __init__(self, input_dim, action_dim, arg, filename=None, hidden_dim=128, gamma=0.99, tau=0.001, memory_size=1e6, device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n",
    "\n",
    "        self.device = device\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.data_path = arg.data_path\n",
    "\n",
    "        print(\"Running Agent: using \", self.device)\n",
    "\n",
    "        self.actor = Actor(input_dim, action_dim).to(self.device)\n",
    "        self.target_actor = Actor(input_dim, action_dim).to(self.device)  # target NW\n",
    "        self.critic = Critic(input_dim, action_dim, hidden_dim).to(self.device)\n",
    "        self.target_critic = Critic(input_dim, action_dim, hidden_dim).to(self.device)# target NW\n",
    "\n",
    "        self.actor_optim = Adam(self.actor.parameters(), lr=1e-4)\n",
    "        self.critic_optim = Adam(self.critic.parameters(), lr=1e-3)\n",
    "\n",
    "        self.priority = False\n",
    "        self.memory = ReplayMemory(int(memory_size), priority=self.priority)\n",
    "\n",
    "        self.args = (input_dim, action_dim, hidden_dim)\n",
    "        hard_update(self.target_actor, self.actor)  # Make sure target is with the same weight\n",
    "        hard_update(self.target_critic, self.critic)\n",
    "        # self.create_save_file(filename)\n",
    "\n",
    "\n",
    "    def select_action(self,  state, action_noise=None, param = None):\n",
    "\n",
    "        state = Variable(state).to(self.device)\n",
    "        \n",
    "        if param is not None:\n",
    "            mu = self.actor_perturbed(state).detach()\n",
    "        else: # no parameter space noise\n",
    "            mu = self.actor(state).detach()\n",
    "\n",
    "        if action_noise is not None:\n",
    "            mu += torch.Tensor(action_noise.noise()).to(self.device)\n",
    "        return mu.clamp(-1, 1)\n",
    "\n",
    "    def update_parameters(self, batch):\n",
    "        states = variable(torch.cat(batch.state))\n",
    "        next_states = variable(torch.cat(batch.next_state))\n",
    "        actions = variable(torch.cat(batch.action))\n",
    "        rewards = variable(torch.cat(batch.reward).unsqueeze(1))\n",
    "        #masks = variable(torch.cat(batch.mask))\n",
    "        dones = variable(torch.cat(batch.done))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_actions = self.target_actor(next_states) # use target\n",
    "            next_qvalues = self.target_critic(next_states, next_actions) # use target network\n",
    "            #next_qvalues = self.target_critic(next_states, next_actions) * (1 - dones)\n",
    "            target_qvalues = rewards + self.gamma * next_qvalues\n",
    "\n",
    "        self.critic_optim.zero_grad()\n",
    "        pred_qvalues = self.critic(states, actions)\n",
    "        value_loss = torch.mean((pred_qvalues - target_qvalues)**2)\n",
    "        value_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        self.actor_optim.zero_grad()\n",
    "        policy_loss = -self.critic(states, self.actor(states))\n",
    "        policy_loss = policy_loss.mean()\n",
    "        policy_loss.backward()\n",
    "        self.actor_optim.step()\n",
    "        return policy_loss, value_loss\n",
    "\n",
    "    def learn(self, epochs=2, batch_size=64):\n",
    "        for epoch in range(epochs):\n",
    "            # sample new batch here\n",
    "            batch, _ = self.memory.sample(batch_size)\n",
    "            losses = self.update_parameters(batch)\n",
    "            soft_update(self.target_actor, self.actor, self.tau)\n",
    "            soft_update(self.target_critic, self.critic, self.tau)\n",
    "\n",
    "        return losses\n",
    "\n",
    "    def save(self, filename, episode):\n",
    "        state = {\n",
    "            'args': self.args,\n",
    "            'actor_dict': self.actor.state_dict(),\n",
    "            'critic_dict': self.critic.state_dict(),\n",
    "        }\n",
    "\n",
    "\n",
    "        torch.save(state, self.file)\n",
    "        if episode % 100 == 0:\n",
    "            print(\"Saved to \" + self.file)\n",
    "\n",
    "    def load(self, filename):\n",
    "        file = self.data_path +'trained_agent/'+filename+'.pth.tar'\n",
    "        state = torch.load(file, map_location=lambda storage, loc: storage)\n",
    "        if self.args != state['args']:\n",
    "            print('Agent parameters from file are different from call')\n",
    "            print('Overwriting agent to load file ... ')\n",
    "            args = state['args']\n",
    "            #self = Agent(*args)\n",
    "            self.__init__(*args)\n",
    "\n",
    "        self.actor.load_state_dict(state['actor_dict'])\n",
    "        self.critic.load_state_dict(state['critic_dict'])\n",
    "        hard_update(self.target_actor, self.actor)  # Make sure target is with the same weight\n",
    "        hard_update(self.target_critic, self.critic)\n",
    "        #print('Loaded')\n",
    "        return\n",
    "\n",
    "    def create_save_file(self, filename):\n",
    "        path = self.data_path+'trained_agent'\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if filename == None:\n",
    "            self.file = next_path(path + '/' + 'ddpgmodel_%s.pth.tar')\n",
    "        else: self.file = path + '/' + filename + '.pth.tar'\n",
    "\n",
    "    def perturb_actor_parameters(self, param_noise):\n",
    "        \"\"\"Apply parameter noise to actor model, for exploration\"\"\"\n",
    "        hard_update(self.actor_perturbed, self.actor)\n",
    "        params = self.actor_perturbed.state_dict()\n",
    "        for name in params:\n",
    "            if 'ln' in name:\n",
    "                pass\n",
    "            param = params[name]\n",
    "            if 'bn' not in name:\n",
    "                random = torch.randn(param.shape).to(self.device)\n",
    "                \n",
    "                param += random * param_noise.current_stddev\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, OBS_DIM, ACTION_DIM, TARGET_DIM, RNN_SIZE, BN_SIZE, FC_SIZE, RNN):\n",
    "        super().__init__()\n",
    "        self.OBS_DIM = OBS_DIM\n",
    "        self.ACTION_DIM = ACTION_DIM\n",
    "        \n",
    "        self.rnn1 = RNN(input_size=OBS_DIM + ACTION_DIM, hidden_size=RNN_SIZE)\n",
    "        self.l1 = nn.Linear(RNN_SIZE, BN_SIZE)\n",
    "        self.l2 = nn.Linear(BN_SIZE + TARGET_DIM, FC_SIZE)\n",
    "        self.l3 = nn.Linear(FC_SIZE, FC_SIZE)\n",
    "        self.l4 = nn.Linear(FC_SIZE, ACTION_DIM)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x, hidden_in, return_hidden=True): \n",
    "        x_v = x[:, :, :self.OBS_DIM + self.ACTION_DIM]\n",
    "        x_tar = x[:, :, self.OBS_DIM + self.ACTION_DIM:]\n",
    "        \n",
    "        if hidden_in is None:\n",
    "            x_v, hidden_out = self.rnn1(x_v)\n",
    "        else:\n",
    "            x_v, hidden_out = self.rnn1(x_v, hidden_in)\n",
    "          \n",
    "        x_v = self.l1(x_v)\n",
    "        x = F.relu(self.l2(torch.cat([x_v, x_tar], dim=2)))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = torch.tanh(self.l4(x))\n",
    "        if return_hidden:\n",
    "            return x, hidden_out\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, OBS_DIM, ACTION_DIM, TARGET_DIM, RNN_SIZE, BN_SIZE, FC_SIZE, RNN):\n",
    "        super().__init__()\n",
    "        self.OBS_DIM = OBS_DIM\n",
    "        self.ACTION_DIM = ACTION_DIM\n",
    "        \n",
    "        # Q1 architecture\n",
    "        self.rnn1 = RNN(input_size=OBS_DIM + ACTION_DIM, hidden_size=RNN_SIZE)\n",
    "        self.l1 = nn.Linear(RNN_SIZE, BN_SIZE)\n",
    "        self.l2 = nn.Linear(BN_SIZE + TARGET_DIM + ACTION_DIM, FC_SIZE)\n",
    "        self.l3 = nn.Linear(FC_SIZE, FC_SIZE)  \n",
    "        self.l4 = nn.Linear(FC_SIZE, 1)\n",
    "        \n",
    "        # Q2 architecture\n",
    "        self.rnn2 = RNN(input_size=OBS_DIM + ACTION_DIM, hidden_size=RNN_SIZE)\n",
    "        self.l5 = nn.Linear(RNN_SIZE, BN_SIZE)\n",
    "        self.l6 = nn.Linear(BN_SIZE + TARGET_DIM + ACTION_DIM, FC_SIZE)\n",
    "        self.l7 = nn.Linear(FC_SIZE, FC_SIZE)\n",
    "        self.l8 = nn.Linear(FC_SIZE, 1)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "\n",
    "    def forward(self, x, u, hidden_in1=None, hidden_in2=None, return_hidden=False):\n",
    "        x_v = x[:, :, :self.OBS_DIM + self.ACTION_DIM]\n",
    "        x_tar = x[:, :, self.OBS_DIM + self.ACTION_DIM:]\n",
    "        \n",
    "        if hidden_in1 is None:\n",
    "            x_v1, hidden_out1 = self.rnn1(x_v)\n",
    "        else:\n",
    "            x_v1, hidden_out1 = self.rnn1(x_v, hidden_in1)\n",
    "        x_v1 = self.l1(x_v1)\n",
    "        x1 = F.relu(self.l2(torch.cat([x_v1, x_tar, u], dim=2)))\n",
    "        x1 = F.relu(self.l3(x1))\n",
    "        x1 = self.l4(x1)\n",
    "        \n",
    "        if hidden_in2 is None:\n",
    "            x_v2, hidden_out2 = self.rnn2(x_v)\n",
    "        else:\n",
    "            x_v2, hidden_out2 = self.rnn2(x_v, hidden_in2)\n",
    "        x_v2 = self.l5(x_v2)\n",
    "        x2 = F.relu(self.l6(torch.cat([x_v2, x_tar, u], dim=2)))\n",
    "        x2 = F.relu(self.l7(x2))\n",
    "        x2 = self.l8(x2)\n",
    "        \n",
    "        if return_hidden:\n",
    "            return x1, x2, hidden_in1, hidden_out2\n",
    "        else:\n",
    "            return x1, x2\n",
    "    \n",
    "    def Q1(self, x, u):\n",
    "        x_v = x[:, :, :self.OBS_DIM + self.ACTION_DIM]\n",
    "        x_tar = x[:, :, self.OBS_DIM + self.ACTION_DIM:]\n",
    "        \n",
    "        x_v1, _ = self.rnn1(x_v)\n",
    "        x_v1 = self.l1(x_v1)\n",
    "        x1 = F.relu(self.l2(torch.cat([x_v1, x_tar, u], dim=2)))\n",
    "        x1 = F.relu(self.l3(x1))\n",
    "        x1 = self.l4(x1)\n",
    "        \n",
    "        return x1\n",
    "\n",
    "transition = namedtuple('transition', ('state', 'action', 'reward'))\n",
    "class ReplayMemory():\n",
    "    def __init__(self, MEMORY_SIZE, BATCH_SIZE):\n",
    "        self.MEMORY_SIZE = MEMORY_SIZE\n",
    "        self.SMALL_MEMORY_SIZE = int(MEMORY_SIZE / 10)\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        # a ring buffer\n",
    "        if len(self.memory) < self.MEMORY_SIZE:\n",
    "            self.memory.append(None)\n",
    "            \n",
    "        self.memory[self.position] = transition(*args)\n",
    "        self.position = (self.position+1) % self.MEMORY_SIZE\n",
    "        \n",
    "    def sample(self):\n",
    "        # 1. Sample a small memory.\n",
    "        if len(self.memory) < self.SMALL_MEMORY_SIZE:\n",
    "            small_memory = self.memory\n",
    "        else:\n",
    "            small_memory = random.sample(self.memory, self.SMALL_MEMORY_SIZE)\n",
    "            \n",
    "        # 2. Sample a trial length.\n",
    "        traj_len = [traj.reward.shape[0] for traj in small_memory]\n",
    "        traj_len = random.sample(traj_len, 1)[0]\n",
    "        \n",
    "        # 3. Get trials with same length.\n",
    "        small_memory = [traj for traj in small_memory if traj.reward.shape[0] == traj_len]\n",
    "        \n",
    "        # 4. Sample a mini batch.\n",
    "        batch = random.sample(small_memory, min(self.BATCH_SIZE, len(small_memory)))\n",
    "        batch = transition(*zip(*batch))\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "    def load(self, memory):          \n",
    "        self.memory, self.position = memory\n",
    "        \n",
    "    def reset(self):\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "class BeliefStep(nn.Module):\n",
    "    def __init__(self, arg):\n",
    "        super().__init__()\n",
    "        self.STATE_DIM = arg.STATE_DIM\n",
    "        self.OBS_DIM = arg.OBS_DIM\n",
    "        self.obs_noise_range = arg.obs_noise_range\n",
    "        \n",
    "        self.H = torch.zeros(self.OBS_DIM, self.STATE_DIM)\n",
    "        self.H[0, 1] = 1\n",
    "        \n",
    "    @property\n",
    "    def obs_noise_range(self):\n",
    "        return self._obs_noise_range\n",
    "    \n",
    "    @obs_noise_range.setter\n",
    "    def obs_noise_range(self, value):\n",
    "        self._obs_noise_range = [0, 0] if value is None else value\n",
    "\n",
    "    def reset(self, pro_gains, obs_noise_std=None):\n",
    "        self.obs_noise_std = obs_noise_std\n",
    "        \n",
    "        if self.obs_noise_std is None:\n",
    "            self.obs_noise_std = torch.zeros(1).uniform_(\n",
    "                                    self.obs_noise_range[0], \n",
    "                                    self.obs_noise_range[1]) * pro_gains\n",
    "\n",
    "    def forward(self, x):\n",
    "        zita = (self.obs_noise_std * torch.randn(self.OBS_DIM)).view([-1, 1])\n",
    "        o_t = self.H @ x + zita\n",
    "        \n",
    "        return o_t\n",
    "\n",
    "class Arg:\n",
    "    def __init__(self) -> None:\n",
    "        self.data_path=None\n",
    "        self.OBS_DIM=1\n",
    "        self.ACTION_DIM=1\n",
    "        self.TARGET_DIM=1\n",
    "        self.RNN_SIZE=2\n",
    "        self.BN_SIZE=1\n",
    "        self.FC_SIZE=1\n",
    "        self.RNN=nn.LSTM\n",
    "        self.device='cpu'\n",
    "        self.optimzer=Adam\n",
    "        self.lr=0.001\n",
    "        self.eps=1e-8\n",
    "        self.MEMORY_SIZE = int(1e5)\n",
    "        self.BATCH_SIZE = 16\n",
    "        self.STATE_DIM = 2\n",
    "        self.ACTION_DIM = 1\n",
    "        self.OBS_DIM = 1\n",
    "        self.TARGET_DIM = 2\n",
    "        self.obs_noise_range = [0, 0.1]\n",
    "\n",
    "arg=Arg()\n",
    "\n",
    "class ActionNoise():\n",
    "    def __init__(self, ACTION_DIM, mean, std=0.1):\n",
    "        self.mu = torch.ones(ACTION_DIM) * mean\n",
    "        self.std = std\n",
    "        self.ACTION_DIM = ACTION_DIM\n",
    "\n",
    "    def reset(self, mean, std):\n",
    "        self.mu = torch.ones(self.ACTION_DIM) * mean\n",
    "        self.std = std\n",
    "\n",
    "    def noise(self):\n",
    "        n = torch.randn(self.ACTION_DIM)\n",
    "        return self.mu + self.std * n\n",
    "    \n",
    "std = 0.1 # this is for action space noise for exploration\n",
    "noise = ActionNoise(1, mean=0., std=std)\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, arg):\n",
    "        self.__dict__ .update(arg.__dict__)\n",
    "        # self.data_path = self.data_path_\n",
    "\n",
    "        self.actor = Actor(self.OBS_DIM, self.ACTION_DIM, self.TARGET_DIM, \n",
    "                           self.RNN_SIZE, self.BN_SIZE, self.FC_SIZE, self.RNN).to(self.device)\n",
    "        self.target_actor = copy.deepcopy(self.actor).to(self.device)\n",
    "        self.target_actor.eval()\n",
    "        self.actor_optim = self.optimzer(self.actor.parameters(), lr=self.lr, eps=self.eps)\n",
    "        \n",
    "        self.critic = Critic(self.OBS_DIM, self.ACTION_DIM, self.TARGET_DIM, \n",
    "                           self.RNN_SIZE, self.BN_SIZE, self.FC_SIZE, self.RNN).to(self.device)\n",
    "        self.target_critic = copy.deepcopy(self.critic).to(self.device)\n",
    "        self.target_critic.eval()\n",
    "        self.critic_optim = self.optimzer(self.critic.parameters(), lr=self.lr, eps=self.eps)\n",
    "        \n",
    "        self.memory = ReplayMemory(arg.MEMORY_SIZE, arg.BATCH_SIZE)\n",
    "        self.bstep = BeliefStep(arg)\n",
    "        \n",
    "        self.initial_episode = 0\n",
    "        self.it = 0\n",
    "\n",
    "    def select_action(self, state, hidden_in, action_noise=None):\n",
    "        with torch.no_grad():\n",
    "            action, hidden_out = self.actor(state, hidden_in)\n",
    "            \n",
    "        action = action.cpu()\n",
    "        action_raw = action.clone()\n",
    "        if (action_noise is not None) and (action_raw.abs() > self.TERMINAL_ACTION).any():\n",
    "            action += action_noise.noise().view_as(action)\n",
    "\n",
    "        return action.clamp(-1, 1), action_raw, hidden_out\n",
    "    \n",
    "    def target_smoothing(self, next_actions):\n",
    "        mask_stop = (next_actions.view(-1, self.ACTION_DIM).abs().max(dim=1).values < self.TERMINAL_ACTION\n",
    "                        ).view(-1, 1).repeat(1, self.ACTION_DIM).view_as(next_actions)\n",
    "        mask_nonstop_pos = (next_actions > self.TERMINAL_ACTION) & (~mask_stop)\n",
    "        mask_nonstop_neg = (next_actions < -self.TERMINAL_ACTION) & (~mask_stop)\n",
    "        mask_nonstop_other = (next_actions.abs() < self.TERMINAL_ACTION) & (~mask_stop)\n",
    "\n",
    "        next_actions[mask_stop] = (next_actions[mask_stop]                         + torch.zeros_like(next_actions[mask_stop]).normal_(\n",
    "                                                mean=0, std=self.policy_noise)\n",
    "                        ).clamp(-self.TERMINAL_ACTION, self.TERMINAL_ACTION)\n",
    "\n",
    "        next_actions[mask_nonstop_pos] = (next_actions[mask_nonstop_pos]                         + torch.zeros_like(next_actions[mask_nonstop_pos]).normal_(\n",
    "                                mean=0, std=self.policy_noise).clamp(-self.policy_noise_clip, self.policy_noise_clip)\n",
    "                        ).clamp(self.TERMINAL_ACTION, 1)\n",
    "\n",
    "        next_actions[mask_nonstop_neg] = (next_actions[mask_nonstop_neg]                         + torch.zeros_like(next_actions[mask_nonstop_neg]).normal_(\n",
    "                                mean=0, std=self.policy_noise).clamp(-self.policy_noise_clip, self.policy_noise_clip)\n",
    "                        ).clamp(-1, -self.TERMINAL_ACTION)\n",
    "\n",
    "        next_actions[mask_nonstop_other] = (next_actions[mask_nonstop_other]                         + torch.zeros_like(next_actions[mask_nonstop_other]).normal_(\n",
    "                                mean=0, std=self.policy_noise).clamp(-self.policy_noise_clip, self.policy_noise_clip)\n",
    "                        ).clamp(-1, 1)\n",
    "        \n",
    "        return next_actions\n",
    "\n",
    "    def update_parameters(self, batch):\n",
    "        states = torch.cat(batch.state, dim=1)\n",
    "        actions =  torch.cat(batch.action, dim=1)\n",
    "        rewards = torch.cat(batch.reward, dim=1)\n",
    "        dones = torch.zeros_like(rewards)\n",
    "        dones[-1] = 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # get next action and apply target policy smoothing\n",
    "            next_states = torch.zeros_like(states)\n",
    "            next_states[:-1] = states[1:]\n",
    "            _, t1_hidden = self.target_actor(states[:1], hidden_in=None, return_hidden=True)\n",
    "            next_actions = self.target_actor(next_states, hidden_in=t1_hidden, return_hidden=False)\n",
    "            next_actions = self.target_smoothing(next_actions)\n",
    "            \n",
    "            # compute the target Q\n",
    "            _, _, t1_hidden1, t1_hidden2 = self.target_critic(states[:1], actions[:1], return_hidden=True)\n",
    "            target_Q1, target_Q2 = self.target_critic(next_states, next_actions, \n",
    "                                                      hidden_in1=t1_hidden1, hidden_in2=t1_hidden2)\n",
    "            target_Q = torch.min(target_Q1, target_Q2)\n",
    "            target_Q = rewards + (1-dones) * self.GAMMA * target_Q\n",
    "\n",
    "        # current Q estimates\n",
    "        current_Q1, current_Q2 = self.critic(states, actions)\n",
    "        critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
    "\n",
    "        # optimize the critic\n",
    "        self.critic_optim.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "        # delay policy updates\n",
    "        if self.it % self.POLICY_FREQ == 0:\n",
    "            # define actor loss\n",
    "            actor_loss = - self.critic.Q1(states, self.actor(states, hidden_in=None, return_hidden=False)).mean()\n",
    "            \n",
    "            # optimize the actor\n",
    "            self.actor_optim.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optim.step()\n",
    "\n",
    "            # update target networks\n",
    "            self.soft_update(self.target_actor, self.actor)\n",
    "            self.soft_update(self.target_critic, self.critic)\n",
    "        else:\n",
    "            actor_loss = torch.tensor([0])\n",
    "\n",
    "        return actor_loss.detach().item(), critic_loss.detach().item()\n",
    "\n",
    "    def learn(self):\n",
    "        batch = self.memory.sample()\n",
    "        loss_logs = self.update_parameters(batch)\n",
    "        self.it += 1\n",
    "        return loss_logs\n",
    "\n",
    "    def save(self, save_memory, episode):\n",
    "        file = self.data_path / f'{self.filename}-{episode}.pth.tar'\n",
    "        \n",
    "        state = {'actor_dict': self.actor.state_dict(),\n",
    "                'critic_dict': self.critic.state_dict(),\n",
    "                'target_actor_dict': self.target_actor.state_dict(),\n",
    "                'target_critic_dict': self.target_critic.state_dict(),\n",
    "                'actor_optimizer_dict': self.actor_optim.state_dict(),\n",
    "                'critic_optimizer_dict': self.critic_optim.state_dict(),\n",
    "                'episode': episode}\n",
    "        \n",
    "        if save_memory:\n",
    "            state['memory'] = (self.memory.memory, self.memory.position)\n",
    "\n",
    "        torch.save(state, file)\n",
    "\n",
    "    def load(self, filename, load_memory, load_optimzer):\n",
    "        self.filename = filename\n",
    "        file = self.data_path / f'{self.filename}.pth.tar'\n",
    "        state = torch.load(file)\n",
    "\n",
    "        self.actor.load_state_dict(state['actor_dict'])\n",
    "        self.critic.load_state_dict(state['critic_dict'])\n",
    "        self.target_actor.load_state_dict(state['target_actor_dict'])\n",
    "        self.target_critic.load_state_dict(state['target_critic_dict'])\n",
    "        self.initial_episode = state['episode']\n",
    "        \n",
    "        if load_memory is True:\n",
    "            self.memory.load(state['memory'])\n",
    "        if load_optimzer is True:\n",
    "            self.actor_optim.load_state_dict(state['actor_optimizer_dict'])\n",
    "            self.critic_optim.load_state_dict(state['critic_optimizer_dict'])\n",
    "\n",
    "    def soft_update(self, target, source):\n",
    "        for target_param, param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(target_param.data * (1 - self.TAU) + param.data * self.TAU)\n",
    "            \n",
    "    def mirror_traj(self, states, actions, mirrored_index=(1, 3, 4)):\n",
    "        # state index 1: w; 3: action aw; 4: target x\n",
    "        states_ = states.clone()\n",
    "        states_[:, :, mirrored_index] = - states_[:, :, mirrored_index]\n",
    "        # 1 of action indexes angular action aw\n",
    "        actions_ = actions.clone()\n",
    "        actions_[:, :, 1] = - actions_[:, :, 1]\n",
    "        \n",
    "        return states_, actions_\n",
    "\n",
    "\n",
    "actual_state_x = np.array([[1.],[0]]) \n",
    "desired_state_xf = np.array([[0.],[0.]])  \n",
    "\n",
    "# agent = Agent(1, 1, arg,  'filename', hidden_dim=128, gamma=0.97, tau=0.001)\n",
    "agent=Agent(arg)\n",
    "actual_state_x = np.array([[1.],[0]]) \n",
    "desired_state_xf = np.array([[0.],[0.]])  \n",
    "env=Task(A, B, H, R, actual_state_x,desired_state_xf, timeout=333)\n",
    "\n",
    "tot_t=0\n",
    "policy_loss_log,value_loss_log=[],[]\n",
    "value_losses = deque(maxlen=500)\n",
    "reward_log=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-23b7bfcf9263>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                          torch.zeros((1, 1, 2), device=arg.device))\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden1_in_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-300-5600a5cb9bef>\u001b[0m in \u001b[0;36mselect_action\u001b[0;34m(self, state, hidden_in, action_noise)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-300-5600a5cb9bef>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden_in, return_hidden)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mx_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBS_DIM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACTION_DIM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mx_tar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOBS_DIM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACTION_DIM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "while tot_t<100:\n",
    "\n",
    "    # one ep\n",
    "    ep_reward=[]\n",
    "    done=False\n",
    "    x=env.reset()\n",
    "    last_action = torch.zeros(1, 1, arg.ACTION_DIM)\n",
    "    state = torch.cat([torch.from_numpy(x[-arg.OBS_DIM:]).float().view(1,1,-1), last_action,\n",
    "                        ], dim=2).to(arg.device)\n",
    "    hidden1_in_policy = (torch.zeros((1, 1, 2), device=arg.device), \n",
    "                         torch.zeros((1, 1, 2), device=arg.device))\n",
    "    while not done:\n",
    "        action = agent.select_action(torch.from_numpy(obs).float(),hidden1_in_policy, action_noise = noise)  \n",
    "        next, reward, done = env.step(np.array(action)) \n",
    "\n",
    "        mask = torch.tensor([1 - float(done)]) # mask = 0: episode is over\n",
    "        agent.memory.push(torch.from_numpy(obs).float(), action, 1 - mask, torch.from_numpy(next).float(), torch.from_numpy(reward).float())\n",
    "        obs=next\n",
    "        ep_reward.append(reward)\n",
    "        if reward>0.001:\n",
    "            print('!')\n",
    "\n",
    "        if len(agent.memory) > 2000:\n",
    "            policy_loss, value_loss = agent.learn(batch_size=500)\n",
    "\n",
    "            policy_loss_log.append(policy_loss.data.clone().item())\n",
    "            value_losses.append(value_loss.data.clone().item())\n",
    "            if len(agent.memory) > 1000 and tot_t % 500 == 0:\n",
    "                value_loss_log.append(np.mean(value_losses))\n",
    "\n",
    "    reward_log.append(sum(ep_reward))\n",
    "    print(sum(ep_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 3x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-3b374b2714b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden1_in_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-294-5ef9c8b42cbd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden_in, return_hidden)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_tar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 3x1)"
     ]
    }
   ],
   "source": [
    "agent.actor(state, hidden1_in_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efbf480ae10>]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "policy_surface=[]\n",
    "for obs in np.linspace(-1,1,20):\n",
    "    obs=obs.reshape(1,1)\n",
    "    action = agent.select_action(torch.from_numpy(obs).float(), action_noise = None, param = None)  \n",
    "    policy_surface.append(obs[0,0])\n",
    "plt.plot(np.linspace(-1,1,20),policy_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'time')"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eval\n",
    "done=False\n",
    "obs=env.reset()\n",
    "while not done:\n",
    "    action = agent.select_action(torch.from_numpy(obs).float(), action_noise = None, param = None) \n",
    "    obs, reward, done = env.step(np.array(action))\n",
    "\n",
    "%matplotlib inline\n",
    "plt.plot([x[0,0] for x in env.xs], 'r', label='state (pos)')\n",
    "plt.plot(np.array(env.us).reshape(-1), label='control')\n",
    "plt.legend()\n",
    "plt.ylabel('quantity au (target = 0)')\n",
    "plt.xlabel('time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
